import * as fs from "fs";
import * as path from "path";
import { GoogleGenAI, Video } from "@google/genai";
import {
  ScriptWithImages,
  SceneWithImage,
  SceneWithVideo,
  FinalOutput,
} from "../types/script.js";

/**
 * VideoGenerationService
 *
 * ä¸ºå‰§æœ¬ä¸­çš„åœºæ™¯ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
 * ä½¿ç”¨ Google Veo 3.1 (Image-to-Video & Extend Video)
 */
export class VideoGenerationService {
  private ai: GoogleGenAI;
  private apiKey: string;
  private outputDir: string;
  private pollInterval: number;

  constructor(options: {
    apiKey: string;
    outputDir?: string;
    pollInterval?: number;
  }) {
    this.apiKey = options.apiKey;
    this.ai = new GoogleGenAI({ apiKey: options.apiKey });
    this.outputDir = options.outputDir || "./output/videos";
    this.pollInterval = options.pollInterval || 10000; // 10 ç§’è½®è¯¢

    // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if (!fs.existsSync(this.outputDir)) {
      fs.mkdirSync(this.outputDir, { recursive: true });
    }
  }

  /**
   * æ„å»ºå®Œæ•´çš„ Veo æç¤ºè¯ï¼ˆåŒ…å«ç”»é¢æè¿° + æ—ç™½ï¼‰
   * Veo 3 æ”¯æŒç”Ÿæˆå¸¦è¯­éŸ³çš„è§†é¢‘
   */
  private buildFullPrompt(scene: SceneWithImage): string {
    // ç»„åˆè§†è§‰æè¿°å’Œæ—ç™½
    // Veo 3 ä¼šæ ¹æ® prompt ä¸­çš„å¯¹è¯/æ—ç™½ç”Ÿæˆç›¸åº”çš„è¯­éŸ³
    return `${scene.visual_description}

Narration (voiceover, clear and engaging tone): "${scene.voiceover}"`;
  }

  /**
   * ä»å›¾ç‰‡ç”Ÿæˆè§†é¢‘ (FRAMES_TO_VIDEO æ¨¡å¼)
   */
  private async generateFromImage(
    prompt: string,
    imageBase64: string,
    sceneId: number
  ): Promise<Video> {
    console.log(`  ğŸ¬ FRAMES_TO_VIDEO: Generating from anchor image...`);

    // ç§»é™¤ data:image/png;base64, å‰ç¼€
    const cleanBase64 = imageBase64.replace(/^data:image\/\w+;base64,/, "");

    let operation = await this.ai.models.generateVideos({
      model: "veo-3.1-generate-preview",
      prompt: prompt,
      image: {
        imageBytes: cleanBase64,
        mimeType: "image/png",
      },
      config: {
        numberOfVideos: 1,
        aspectRatio: "16:9",
      },
    });

    // è½®è¯¢ç­‰å¾…å®Œæˆ
    while (!operation.done) {
      console.log(`  â³ Waiting for video generation (scene ${sceneId})...`);
      await new Promise((resolve) => setTimeout(resolve, this.pollInterval));
      operation = await this.ai.operations.getVideosOperation({ operation });
    }

    const video = operation.response?.generatedVideos?.[0]?.video;
    if (!video) {
      throw new Error(`No video generated for scene ${sceneId}`);
    }

    return video;
  }

  /**
   * æ‰©å±•å·²æœ‰è§†é¢‘ (EXTEND_VIDEO æ¨¡å¼)
   */
  private async extendVideo(
    prompt: string,
    inputVideo: Video,
    sceneId: number
  ): Promise<Video> {
    console.log(`  ğŸ”„ EXTEND_VIDEO: Extending previous video...`);

    let operation = await this.ai.models.generateVideos({
      model: "veo-3.1-generate-preview",
      prompt: prompt,
      video: inputVideo,
      config: {
        numberOfVideos: 1,
        // EXTEND_VIDEO æ¨¡å¼ä¸éœ€è¦ aspectRatio
      },
    });

    // è½®è¯¢ç­‰å¾…å®Œæˆ
    while (!operation.done) {
      console.log(`  â³ Waiting for video extension (scene ${sceneId})...`);
      await new Promise((resolve) => setTimeout(resolve, this.pollInterval));
      operation = await this.ai.operations.getVideosOperation({ operation });
    }

    const video = operation.response?.generatedVideos?.[0]?.video;
    if (!video) {
      throw new Error(`No video generated for scene ${sceneId}`);
    }

    return video;
  }

  /**
   * ä¸‹è½½è§†é¢‘æ–‡ä»¶
   */
  private async downloadVideo(
    videoUri: string,
    outputPath: string
  ): Promise<void> {
    console.log(`  ğŸ“¥ Downloading video...`);

    const url = decodeURIComponent(videoUri);
    const fetchUrl = url.includes("?")
      ? `${url}&key=${this.apiKey}`
      : `${url}?key=${this.apiKey}`;

    const res = await fetch(fetchUrl);

    if (!res.ok) {
      throw new Error(`Failed to fetch video: ${res.status} ${res.statusText}`);
    }

    const videoBlob = await res.blob();
    const buffer = Buffer.from(await videoBlob.arrayBuffer());
    fs.writeFileSync(outputPath, buffer);

    console.log(`  âœ… Video saved: ${outputPath}`);
  }

  /**
   * ä¸»å‡½æ•°ï¼šä¸ºå‰§æœ¬ç”Ÿæˆè§†é¢‘
   */
  async generateVideos(script: ScriptWithImages): Promise<FinalOutput> {
    console.log("ğŸ¥ Starting video generation...");
    console.log(`ğŸ“Š Total scenes: ${script.scenes.length}`);
    console.log(`ğŸ¨ Style: ${script.style}`);
    console.log();

    const scenesWithVideo: SceneWithVideo[] = [];
    let previousVideo: Video | null = null;

    for (let i = 0; i < script.scenes.length; i++) {
      const scene = script.scenes[i];
      const isFirstScene = i === 0;

      console.log(`â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
      console.log(`ğŸ“ Scene ${scene.id} (${scene.timestamp}):`);
      console.log(`   Motion: ${scene.motion_intensity}`);
      console.log(`   Has anchor image: ${scene.image_base64 !== null}`);
      console.log(`   Voiceover: "${scene.voiceover.substring(0, 50)}..."`);

      let video: Video;
      const videoPath = path.join(this.outputDir, `scene_${scene.id}.mp4`);

      // æ„å»ºåŒ…å«æ—ç™½çš„å®Œæ•´ prompt
      const fullPrompt = this.buildFullPrompt(scene);

      try {
        if (scene.image_base64 !== null) {
          // æœ‰é”šç‚¹å›¾ â†’ FRAMES_TO_VIDEO
          video = await this.generateFromImage(
            fullPrompt,
            scene.image_base64,
            scene.id
          );
        } else if (previousVideo !== null) {
          // æ— é”šç‚¹å›¾ä½†æœ‰ä¸Šä¸€æ®µè§†é¢‘ â†’ EXTEND_VIDEO
          video = await this.extendVideo(
            fullPrompt,
            previousVideo,
            scene.id
          );
        } else if (isFirstScene) {
          // ç¬¬ä¸€ä¸ªåœºæ™¯æ²¡æœ‰é”šç‚¹å›¾ â†’ æŠ¥é”™
          throw new Error(
            "First scene must have an anchor image (image_base64)"
          );
        } else {
          // ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
          throw new Error(
            `Scene ${scene.id} has no anchor image and no previous video`
          );
        }

        // ä¸‹è½½è§†é¢‘
        if (video.uri) {
          await this.downloadVideo(video.uri, videoPath);
        } else {
          throw new Error(`Video URI is missing for scene ${scene.id}`);
        }

        // ä¿å­˜å½“å‰è§†é¢‘å¯¹è±¡ä¾›ä¸‹ä¸€æ¬¡æ‰©å±•ä½¿ç”¨
        previousVideo = video;

        // æ·»åŠ åˆ°ç»“æœ
        scenesWithVideo.push({
          ...scene,
          video_path: videoPath,
          video_uri: video.uri,
        });

        console.log(`   âœ… Scene ${scene.id} completed!`);
      } catch (error) {
        console.error(`   âŒ Failed to generate video for scene ${scene.id}:`);
        console.error(error);
        throw error;
      }

      console.log();
    }

    console.log("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    console.log(`âœ… Video generation complete!`);
    console.log(`   Total videos: ${scenesWithVideo.length}`);

    return {
      title: script.title,
      scientific_field: script.scientific_field,
      style: script.style,
      scenes: scenesWithVideo,
    };
  }
}
